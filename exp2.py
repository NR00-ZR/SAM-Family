import torch
from ultralytics import SAM
import cv2
import os
import time

video_path = "/data2/zhuangyn/04.mp4" 
SNAPSHOT_INTERVAL = 5   # è®¾ç½®æˆªå›¾é—´éš”
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"\nğŸš€å¼€å§‹éªŒè¯ SAM 2 è§†é¢‘å¤„ç†èƒ½åŠ› (æ¯ {SNAPSHOT_INTERVAL} å¸§ä¿å­˜ä¸€æ¬¡æˆªå›¾)...")

# å¯¹æ¯”æ¨¡å‹
video_models = [
    {"name": "SAM 1 (Base)", "file": "sam_b.pt"},
    {"name": "SAM 2 (Base)", "file": "sam2_b.pt"} 
]

video_stats = []

for config in video_models:
    model_name = config['name']
    model_file = config['file']
    
    # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
    safe_name = model_name.replace(" ", "_").replace("(", "").replace(")", "")
    print(f"\n--> æ­£åœ¨è¿è¡Œ {model_name} ...")
    
    try:
        model = SAM(model_file)
        t0 = time.time()
    
        # ä½¿ç”¨ track æ¨¡å¼ä»¥å¯ç”¨è§†é¢‘æµå¼å¤„ç†å’Œè®°å¿†åŠŸèƒ½
        results = model.track(
            source=video_path, 
            persist=True,        # å¼€å¯æŒä¹…åŒ–è¿½è¸ª 
            stream=True,         # æµå¼ç”Ÿæˆå™¨ï¼ŒèŠ‚çœå†…å­˜
            device=device, 
            verbose=False,
            save=True,           # ä¿å­˜è§†é¢‘
            project="runs/comparison",
            name=safe_name,      
            exist_ok=True        
        )
        
        frame_idx = 0
        processed_frames = 0

        for r in results:
            frame_idx += 1
            processed_frames += 1
     
            if frame_idx % SNAPSHOT_INTERVAL == 0:
                # æ–‡ä»¶åä¾‹å¦‚: video_frame_005_SAM_1_Base.jpg
                save_img_name = f"video_frame_{frame_idx:03d}_{safe_name}.jpg"
                
                # ç»˜åˆ¶å¹¶ä¿å­˜å›¾ç‰‡
                res_img = r.plot()
                cv2.imwrite(save_img_name, res_img)
                
                # åªæ‰“å°å…³é”®èŠ‚ç‚¹çš„æç¤ºï¼Œé¿å…åˆ·å±
                if frame_idx % 20 == 0:
                    print(f"    [è¿›åº¦] å·²å¤„ç† {frame_idx} å¸§ï¼Œæœ€æ–°æˆªå›¾: {save_img_name}")

        t1 = time.time()
        
        # è®¡ç®— FPS
        if processed_frames > 0:
            total_time = t1 - t0
            fps = processed_frames / total_time
            video_stats.append({"Model": model_name, "FPS": f"{fps:.2f}"})
            print(f"å®Œæˆã€‚ä¿å­˜è·¯å¾„: runs/comparison/{safe_name}/{os.path.basename(video_path)}")
            print(f"è€—æ—¶: {total_time:.2f}s, å¹³å‡ FPS: {fps:.2f}")

    except Exception as e:
        print(f"è¿è¡Œå‡ºé”™: {e}")

print("\n" + "="*60)
print("[å®éªŒæ•°æ®æ±‡æ€»]")
print("="*60)

if not video_stats:
    print("æ²¡æœ‰æ”¶é›†åˆ°å®éªŒæ•°æ®ã€‚")
else:
    print(f"{'æ¨¡å‹åç§°':<20} | {'FPS (å¤„ç†é€Ÿåº¦)':<15}")
    print("-" * 40)
    for stat in video_stats:
        print(f"{stat['Model']:<20} | {stat['FPS']:<15}")

print("\n æˆªå›¾å·²ä¿å­˜åœ¨å½“å‰ç›®å½•ä¸‹ï¼Œè¯·æŸ¥çœ‹ video_frame_xxx.jpg")
print("="*60)